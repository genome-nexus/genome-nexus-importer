# 1. Mapping by protein sequence: ENST -> ENSP -> Ensembl sequence = UniProt sequence -> UniProt id
# Sequence from Ensembl:
# GRCh37: http://ftp.ensembl.org/pub/grch37/release-101/fasta/homo_sapiens/pep/ rename to ensembl_grch37.fa.gz
# GRCh38: http://ftp.ensembl.org/pub/release-101/fasta/homo_sapiens/pep/ rename to ensembl_grch38.fa.gz
# Sequence from UniProt: https://www.uniprot.org/uniprot/?query=+reviewed%3Ayes+AND+organism%3A%22Homo+sapiens+%28Human%29+%5B9606%5D%22&sort=score
# 2. handle multiple UniProt cases
# Biomart mapping
# GRCh37: https://grch37.ensembl.org/biomart/martview/145410cb02e693b9da427f9c3dffe61f
# GRCh38: http://uswest.ensembl.org/biomart/martview/84262bd39b9c7d095757b6ce493a2a9f
# Reviewed map:
# GRCh37: https://docs.google.com/spreadsheets/d/14PN6RtFq_GTAu8OKNUyUNKJ_fj7OlcEhDjbMdapqqo8/edit#gid=133083142
# GRCh38: https://docs.google.com/spreadsheets/d/1slDx9zorUuA-xsmH1i9_6CIGjQB1GIgDlWDU5gw6f9I/edit#gid=1399879714
# Output:
# "grch3x_ensemblxx_enst_to_uniprot_mapping_full.txt" is the full spreadsheet generated by the script, it contains all review process columns
# "grch3x_ensemblxx_enst_to_uniprot_mapping_id.txt" is the mapping file with only enst column and uniprot mapping column

import json
import re
import pandas as pd
import numpy as np
from Bio import SeqIO
import wget
import requests
from io import StringIO
import time
from collections import OrderedDict
import argparse
import subprocess

# generate sequence to uniprot id dictionary
def generate_dict(key, value, dictionary):
    if key not in dictionary:
        dictionary[key] = []
    dictionary[key].append(value)

def generate_uniprot_protein_length(ensp, dictionary, sequence_to_uniprot_dict):
    if ensp in dictionary:
        seq = dictionary[ensp][0]
        if seq in sequence_to_uniprot_dict:
            return str(len(seq))
    return ''

def generate_identical_sequence(row):
    return len(row['uniprot_protein_length']) != 0

def generate_uniprot_id(ensp, dictionary, sequence_to_uniprot_dict, uniprot_set):
    if ensp in dictionary:
        seq = dictionary[ensp][0]
        if seq in sequence_to_uniprot_dict:
            uniprot_set.add(seq)
            uniprot = ','.join(sequence_to_uniprot_dict[seq])
            return uniprot
    return ''

def generate_biomart_uniprot(ensp, dictionary):
    if ensp in dictionary:
        return dictionary[ensp]
    return ''

def count_uniprot_id(uniprot):
    if uniprot == "":
        return 0
    else:
        return uniprot.count(",") + 1

def is_matched_id(uniprot_sequence, uniprot_biomart):
    return uniprot_sequence == uniprot_biomart
    
def final_mapping(correction_mapping, ensp, uniprot):
    if ensp in correction_mapping:
        return correction_mapping[ensp][0]
    return uniprot

def get_uniprot_from_biomart(df_transcript, biomart_ensp_to_uniprot_dict, genome_build):
    start = 0
    end = 0
    max_length = len(df_transcript)
    chunk = 400
    while (start < max_length):
        if (start + chunk) >= max_length:
            end = max_length
        else:
            end = start + chunk
        ensp_list = []
        print("Fetching BioMart for variant #" + str(start) + " to #" + str(end) + ', ' + str(max_length) + ' in total')
        for i in range(start, end):
            if df_transcript['ensp_id'][i] != '':
                ensp_list.append(df_transcript['ensp_id'][i])
        if len(ensp_list) == 0:
            start = start + chunk
            continue
        if 'grch37' in genome_build.lower():
            url = "http://grch37.ensembl.org/biomart/martservice?query=%3C?xml%20version=%221.0%22%20encoding=%22UTF-8%22?%3E%20%3C!DOCTYPE%20Query%3E%20%3CQuery%20%20virtualSchemaName%20=%20%22default%22%20formatter%20=%20%22TSV%22%20header%20=%20%220%22%20uniqueRows%20=%20%220%22%20count%20=%20%22%22%20datasetConfigVersion%20=%20%220.6%22%20%3E%20%3CDataset%20name%20=%20%22hsapiens_gene_ensembl%22%20interface%20=%20%22default%22%20%3E%20%3CFilter%20name%20=%20%22ensembl_peptide_id%22%20value%20=%20%22" + ','.join(ensp_list) + "%22/%3E%20%3CAttribute%20name%20=%20%22uniprotswissprot%22%20/%3E%20%3CAttribute%20name%20=%20%22ensembl_peptide_id%22%20/%3E%20%3C/Dataset%3E%20%3C/Query%3E"
        else:
            url = "http://www.ensembl.org/biomart/martservice?query=%3C?xml%20version=%221.0%22%20encoding=%22UTF-8%22?%3E%20%3C!DOCTYPE%20Query%3E%20%3CQuery%20%20virtualSchemaName%20=%20%22default%22%20formatter%20=%20%22TSV%22%20header%20=%20%220%22%20uniqueRows%20=%20%220%22%20count%20=%20%22%22%20datasetConfigVersion%20=%20%220.6%22%20%3E%20%3CDataset%20name%20=%20%22hsapiens_gene_ensembl%22%20interface%20=%20%22default%22%20%3E%20%3CFilter%20name%20=%20%22ensembl_peptide_id%22%20value%20=%20%22" + ','.join(ensp_list) + "%22/%3E%20%3CAttribute%20name%20=%20%22uniprotswissprot%22%20/%3E%20%3CAttribute%20name%20=%20%22ensembl_peptide_id%22%20/%3E%20%3C/Dataset%3E%20%3C/Query%3E"
        html = requests.get(url).text
        if "ERROR" in html:
            print ("retry: " + str(start) + " to " + str(end))
            time.sleep(10)
            continue
        parsed_html = html.split('\n')
        for uniprot_with_ensp in parsed_html[:-1]:
            uniprot = uniprot_with_ensp.split('\t')[0]
            ensp = uniprot_with_ensp.split('\t')[1]
            biomart_ensp_to_uniprot_dict[ensp] = uniprot
        start = start + chunk


def main(ensembl_biomart_transcripts, ensembl_fasta, uniprot_id_with_sequence, genome_build_version):
    # extract transcripts
    transcript = open(ensembl_biomart_transcripts)
    if 'grch37' in genome_build_version.lower():
        genome_build = 'grch37'
    else:
        genome_build = 'grch38'
    # get result dataframe from transcript json file
    df_transcript = None
    transcript_ids = []
    protein_ids = []
    protein_lengths = []
    ccds_ids = []
    for line in transcript:
        data = json.loads(line)
        transcript_ids.append(data['transcript_stable_id'] if data['transcript_stable_id'] is not None else "")
        protein_ids.append(data['protein_stable_id'] if data['protein_stable_id'] is not None else "")
        protein_lengths.append(data['protein_length'] if data['protein_length'] is not None else "")
        ccds_ids.append(data['ccds_id'] if data['ccds_id'] is not None else "")
    d = {'enst_id': transcript_ids, 'ensp_id': protein_ids, 'ensembl_protein_length': protein_lengths, 'ccds_id': ccds_ids }
    df_transcript = pd.DataFrame(d)

    # generate ensembl sequence map
    fasta_sequences = SeqIO.parse(open(ensembl_fasta),'fasta')
    ensembl_to_sequence_dict = dict()
    for fasta in fasta_sequences:
        id, sequence = fasta.id, str(fasta.seq)
        # ensembl_to_sequence_dict[ensp] = [sequence, sub_version]
        ensembl_to_sequence_dict[id[:-2]] = [sequence, id[len(id) - 1: len(id)]]

    # get sequence from uniprot
    df_uniprot_id_with_sequence = pd.read_csv(uniprot_id_with_sequence, sep='\t')
    sequence_to_uniprot_dict = dict()
    df_uniprot_id_with_sequence.apply(lambda row: generate_dict(row['Sequence'], row['Entry'], sequence_to_uniprot_dict), axis=1)
    uniprot_set = set()
    biomart_ensp_to_uniprot_dict = dict()
    get_uniprot_from_biomart(df_transcript, biomart_ensp_to_uniprot_dict, genome_build)


    # get correction mapping
    curation_map = '../data/uniprot/input/reviewed_map_' + genome_build.lower() + '.tsv'
    df_transcript_to_uniprot_correction_mapping = pd.read_csv(curation_map, sep='\t')
    correction_dict = dict()
    df_transcript_to_uniprot_correction_mapping.apply(lambda row: generate_dict(row['ensp_id'], row['Final_mapping_uniprot_id'], correction_dict), axis=1)
    df_transcript['uniprot_protein_length'] = df_transcript.apply(lambda row: generate_uniprot_protein_length(row['ensp_id'], ensembl_to_sequence_dict, sequence_to_uniprot_dict), axis = 1)
    df_transcript['identical_sequence'] = df_transcript.apply(generate_identical_sequence, axis = 1)
    df_transcript['uniprot_id'] = df_transcript.apply(lambda row: generate_uniprot_id(row['ensp_id'], ensembl_to_sequence_dict, sequence_to_uniprot_dict, uniprot_set), axis = 1)
    df_transcript['biomart_uniprot_id'] = df_transcript.apply(lambda row: generate_biomart_uniprot(row['ensp_id'], biomart_ensp_to_uniprot_dict), axis = 1)
    df_transcript['uniprot_id_count'] = df_transcript.apply(lambda row: count_uniprot_id(row['uniprot_id']), axis = 1)
    df_transcript['is_matched'] = df_transcript.apply(lambda row: is_matched_id(row['uniprot_id'], row['biomart_uniprot_id']), axis = 1)
    df_transcript['reviewed_uniprot_accession'] = df_transcript.apply(lambda row: final_mapping(correction_dict, row['ensp_id'], row['uniprot_id']), axis = 1)

    # summary
    total_transcripts = np.count_nonzero(df_transcript['enst_id'])
    have_ensp = np.count_nonzero(df_transcript['ensp_id'])
    map_to_uniprot = np.count_nonzero(df_transcript['uniprot_id'])
    map_to_uniprot_by_biomart = np.count_nonzero(df_transcript['biomart_uniprot_id'])

    print ("Results:")
    print (str(total_transcripts) + " transcripts in total")
    print (str(have_ensp) + " have ensp id: " + str(have_ensp/total_transcripts * 100) + "%")
    print (str(map_to_uniprot) + " have been mapped to uniprot successfully")
    print (str(map_to_uniprot/have_ensp * 100) + "% of ensp can be mapped to uniprot, " + str(map_to_uniprot/total_transcripts * 100) + "% overall success rate")
    print ("there are " + str(len(sequence_to_uniprot_dict)) + " unique sequence from 20375 uniprot")
    print (str(len(uniprot_set)) + " sequences can be mapped: " + str(len(uniprot_set)/len(sequence_to_uniprot_dict)*100) + "%")
    print (str(map_to_uniprot_by_biomart) + " transcripts can be mapped by BioMart: " + str(map_to_uniprot_by_biomart / total_transcripts * 100) + "%")

    # Save output file
    full_mapping_file_name = '../data/uniprot/export/' + genome_build_version + '_enst_to_uniprot_mapping_full.txt'
    id_mapping_file_name = '../data/uniprot/export/' + genome_build_version + '_enst_to_uniprot_mapping_id.txt'

    df_transcript.to_csv(full_mapping_file_name, index=False, sep='\t', header=True)
    df_transcript.to_csv(id_mapping_file_name, columns=['enst_id','reviewed_uniprot_accession'], index=False, sep='\t', header=True)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("ensembl_biomart_transcripts",
                        help="../data/grch37_ensembl92/export/ensembl_biomart_transcripts.json")
    parser.add_argument("ensembl_fasta",
                        help="../data/uniprot/input/ensembl_grch37.fa")
    parser.add_argument("uniprot_id_with_sequence",
                        help="../data/uniprot/input/uniprot_id_with_sequence.tab")
    parser.add_argument("genome_build_version",
                        help="grch37_ensembl92 or grch38_ensembl92 or grch38_ensembl95")
    args = parser.parse_args()
    main(args.ensembl_biomart_transcripts, args.ensembl_fasta, args.uniprot_id_with_sequence, args.genome_build_version)
